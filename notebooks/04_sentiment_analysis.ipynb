{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2026-01-02T15:09:12.729503Z",
     "start_time": "2026-01-02T14:43:32.897462Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "from hazm import Normalizer, word_tokenize, stopwords_list\n",
    "from tqdm import tqdm  # <--- Changed from tqdm.auto to just tqdm\n",
    "\n",
    "# Force text-mode progress bar for Pandas\n",
    "tqdm.pandas(bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]')\n",
    "\n",
    "# Load Data\n",
    "df = pd.read_csv('../data/processed/clean_data.csv')\n",
    "\n",
    "# Tools\n",
    "normalizer = Normalizer()\n",
    "stop_words = set(stopwords_list())\n",
    "\n",
    "def preprocess_step_1(text):\n",
    "    if not isinstance(text, str): return []\n",
    "    try:\n",
    "        # 1. Normalize\n",
    "        text = normalizer.normalize(text)\n",
    "        # 2. Tokenize\n",
    "        tokens = word_tokenize(text)\n",
    "        # 3. Stopword Removal\n",
    "        clean_tokens = [t for t in tokens if t not in stop_words]\n",
    "        return clean_tokens\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "print(\"Running Preprocessing ...\")\n",
    "\n",
    "df['clean_tokens_list'] = df['comment_text'].progress_apply(preprocess_step_1)\n",
    "\n",
    "print(\"Process Complete.\")\n",
    "print(df[['comment_text', 'clean_tokens_list']].head(2))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Preprocessing ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4548/4548 [25:38<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Complete.\n",
      "                                        comment_text  \\\n",
      "0                                چیزی اضافه ایی نیست   \n",
      "1  خوب درس نمیده اصلا، نمره ها رو خوب نمیده و اصل...   \n",
      "\n",
      "                                   clean_tokens_list  \n",
      "0                                       [اضافه, ایی]  \n",
      "1  [درس, نمیده, اصلا, ،, نمره‌ها, نمیده, اصلا, تر...  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T15:10:28.037816Z",
     "start_time": "2026-01-02T15:10:27.843200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "#            Simple Rule-Based Sentiment\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. Define Lexicons (Keywords)\n",
    "# We add Persian keywords common in student feedback\n",
    "positive_keywords = {\n",
    "    'خوب', 'عالی', 'بهترین', 'راضی', 'مفید', 'مهربان', \n",
    "    'با‌سواد', 'محترم', 'قوی', 'منصف', '۲۰', '20', 'تشکر',\n",
    "    'استاد نمونه', 'خوش برخورد', 'مسلط'\n",
    "}\n",
    "\n",
    "negative_keywords = {\n",
    "    'بد', 'ضعیف', 'بی‌کیفیت', 'افتضاح', 'حیف', 'بی‌سواد', \n",
    "    'نامرد', 'سخت‌گیر', 'بی‌مسئولیت', 'خسته', 'الکی', 'نمی‌دهد',\n",
    "    'عقده ای', 'پاس نمیکنه', 'میندازه', 'نمره نمیده'\n",
    "}\n",
    "\n",
    "# 2. Define the Rule-Based Function\n",
    "def get_simple_sentiment(tokens):\n",
    "    score = 0\n",
    "    # Safety check: ensure we have a list\n",
    "    if not isinstance(tokens, list): return 'Neutral', 0\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token in positive_keywords:\n",
    "            score += 1\n",
    "        elif token in negative_keywords:\n",
    "            score -= 1\n",
    "            \n",
    "    # Determine Label\n",
    "    if score > 0:\n",
    "        label = 'Positive'\n",
    "    elif score < 0:\n",
    "        label = 'Negative'\n",
    "    else:\n",
    "        label = 'Neutral'\n",
    "        \n",
    "    return label, score\n",
    "\n",
    "# 3. Apply to DataFrame\n",
    "\n",
    "# Note: This runs very fast (seconds)\n",
    "df[['simple_label', 'simple_score']] = df['clean_tokens_list'].progress_apply(\n",
    "    lambda x: pd.Series(get_simple_sentiment(x))\n",
    ")\n",
    "\n",
    "print(\"Process Complete.\")\n",
    "print(\"Distribution of Simple Labels:\")\n",
    "print(df['simple_label'].value_counts())"
   ],
   "id": "5822b5e02b4e8f5a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4548/4548 [00:00<00:00]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Complete.\n",
      "Distribution of Simple Labels:\n",
      "simple_label\n",
      "Neutral     3703\n",
      "Positive     483\n",
      "Negative     362\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T15:16:46.343212Z",
     "start_time": "2026-01-02T15:10:30.988695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "#                 ParsBERT Sentiment\n",
    "# ---------------------------------------------------------\n",
    "import os\n",
    "from transformers import pipeline, AutoModelForSequenceClassification, AutoTokenizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# 1. Configuration\n",
    "HUB_MODEL_ID = \"HooshvareLab/bert-fa-base-uncased-sentiment-digikala\"\n",
    "LOCAL_MODEL_PATH = \"../models/parsbert_sentiment\"\n",
    "\n",
    "def load_sentiment_pipeline():\n",
    "    # --- SAFETY: Create the folder if it doesn't exist ---\n",
    "    if not os.path.exists(LOCAL_MODEL_PATH):\n",
    "        os.makedirs(LOCAL_MODEL_PATH, exist_ok=True)\n",
    "    # -----------------------------------------------------\n",
    "\n",
    "    # Check if files already exist inside\n",
    "    if os.listdir(LOCAL_MODEL_PATH):\n",
    "        print(f\"Found local model at '{LOCAL_MODEL_PATH}'. Loading from disk...\")\n",
    "        model_source = LOCAL_MODEL_PATH\n",
    "    else:\n",
    "        print(f\"Local model not found. Downloading from Hugging Face (~450MB)...\")\n",
    "        model_source = HUB_MODEL_ID\n",
    "    \n",
    "    # Load Model & Tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_source)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_source)\n",
    "    \n",
    "    # Save to disk if we just downloaded it\n",
    "    if model_source == HUB_MODEL_ID:\n",
    "        print(f\"Saving model to '{LOCAL_MODEL_PATH}'...\")\n",
    "        tokenizer.save_pretrained(LOCAL_MODEL_PATH)\n",
    "        model.save_pretrained(LOCAL_MODEL_PATH)\n",
    "        print(\"Model saved successfully.\")\n",
    "\n",
    "    return pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "# 2. Initialize\n",
    "sentiment_pipeline = load_sentiment_pipeline()\n",
    "\n",
    "# 3. Define Helper\n",
    "def get_bert_sentiment(text):\n",
    "    if not isinstance(text, str) or len(text.strip()) < 2:\n",
    "        return \"Neutral\", 0.0\n",
    "    \n",
    "    # Truncate to 1000 chars (approx 200-300 words)\n",
    "    safe_text = text[:1000]\n",
    "    \n",
    "    try:\n",
    "        result = sentiment_pipeline(safe_text, truncation=True, max_length=512)[0]\n",
    "        label = result['label']\n",
    "        score = result['score']\n",
    "        \n",
    "        if label == 'recommended':\n",
    "            return 'Positive', score\n",
    "        elif label == 'not_recommended':\n",
    "            return 'Negative', -score\n",
    "        elif label == 'no_idea':\n",
    "            return 'Neutral', 0\n",
    "        else:\n",
    "            return label, score\n",
    "    except:\n",
    "        return \"Error\", 0\n",
    "\n",
    "# 4. Run Inference\n",
    "tqdm.pandas(desc=\"Running ParsBERT\")\n",
    "print(\"Running AI on 4,500 rows ...\")\n",
    "\n",
    "df[['bert_label', 'bert_score']] = df['clean_comment_text'].progress_apply(\n",
    "    lambda x: pd.Series(get_bert_sentiment(x))\n",
    ")\n",
    "\n",
    "print(\"Process Complete!\")\n",
    "display(df[['clean_comment_text', 'simple_label', 'bert_label']].head(10))"
   ],
   "id": "644be19a7b824172",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found local model at '../models/parsbert_sentiment'. Loading from disk...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running AI on 4,500 rows ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running ParsBERT: 100%|██████████| 4548/4548 [06:15<00:00, 12.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                  clean_comment_text simple_label bert_label\n",
       "0                                چیزی اضافه ایی نیست      Neutral   Negative\n",
       "1  خوب درس نمیده اصلا، نمره ها رو خوب نمیده و اصل...      Neutral   Negative\n",
       "2  در کل اگر که دنبال یک استاد با ادب با دانشجو م...      Neutral   Positive\n",
       "3                                  سخت گیر و پربازده     Negative   Positive\n",
       "4                                چیزی اضافه ایی نیست      Neutral   Negative\n",
       "5  دقت کنید هر جلسه مطالب را بخونید ارشد شب امتحا...      Neutral   Positive\n",
       "6                                چیزی اضافه ایی نیست      Neutral   Negative\n",
       "7  اعصابی براتون نمیمونه چه نمره خوبی بگیرید چه ب...      Neutral    Neutral\n",
       "8  استاد خوبی هستند فقط امتحان های سختی میگیرن که...      Neutral   Positive\n",
       "9             سعی کنید سر کلاس خوب گوش بدید به مطالب      Neutral   Positive"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment_text</th>\n",
       "      <th>simple_label</th>\n",
       "      <th>bert_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>چیزی اضافه ایی نیست</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>خوب درس نمیده اصلا، نمره ها رو خوب نمیده و اصل...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>در کل اگر که دنبال یک استاد با ادب با دانشجو م...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>سخت گیر و پربازده</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>چیزی اضافه ایی نیست</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>دقت کنید هر جلسه مطالب را بخونید ارشد شب امتحا...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>چیزی اضافه ایی نیست</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>اعصابی براتون نمیمونه چه نمره خوبی بگیرید چه ب...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>استاد خوبی هستند فقط امتحان های سختی میگیرن که...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>سعی کنید سر کلاس خوب گوش بدید به مطالب</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T15:20:08.661558Z",
     "start_time": "2026-01-02T15:20:08.642154Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "#                   FINAL COMPARISON\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# 1. View the Raw Comparison\n",
    "print(\"Comparison of Methods:\")\n",
    "print(df[['clean_comment_text', 'simple_label', 'bert_label']].head(10))\n",
    "\n",
    "# 2. Find the \"Disagreements\" (Where AI is smarter!)\n",
    "# We filter for rows where the Simple Method failed (Neutral) but AI found meaning\n",
    "mask_improved = (df['simple_label'] == 'Neutral') & (df['bert_label'] != 'Neutral')\n",
    "\n",
    "print(f\"\\nInsight: The AI found sentiment in {mask_improved.sum()} rows that the Simple Method missed!\")\n",
    "\n",
    "# Show 5 examples where AI was smarter\n",
    "print(\"\\n--- Examples where AI was smarter ---\")\n",
    "display(df.loc[mask_improved, ['clean_comment_text', 'simple_label', 'bert_label']].head(5))"
   ],
   "id": "f4908982d8487693",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of Methods:\n",
      "                                  clean_comment_text simple_label bert_label\n",
      "0                                چیزی اضافه ایی نیست      Neutral   Negative\n",
      "1  خوب درس نمیده اصلا، نمره ها رو خوب نمیده و اصل...      Neutral   Negative\n",
      "2  در کل اگر که دنبال یک استاد با ادب با دانشجو م...      Neutral   Positive\n",
      "3                                  سخت گیر و پربازده     Negative   Positive\n",
      "4                                چیزی اضافه ایی نیست      Neutral   Negative\n",
      "5  دقت کنید هر جلسه مطالب را بخونید ارشد شب امتحا...      Neutral   Positive\n",
      "6                                چیزی اضافه ایی نیست      Neutral   Negative\n",
      "7  اعصابی براتون نمیمونه چه نمره خوبی بگیرید چه ب...      Neutral    Neutral\n",
      "8  استاد خوبی هستند فقط امتحان های سختی میگیرن که...      Neutral   Positive\n",
      "9             سعی کنید سر کلاس خوب گوش بدید به مطالب      Neutral   Positive\n",
      "\n",
      "Insight: The AI found sentiment in 2832 rows that the Simple Method missed!\n",
      "\n",
      "--- Examples where AI was smarter ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                  clean_comment_text simple_label bert_label\n",
       "0                                چیزی اضافه ایی نیست      Neutral   Negative\n",
       "1  خوب درس نمیده اصلا، نمره ها رو خوب نمیده و اصل...      Neutral   Negative\n",
       "2  در کل اگر که دنبال یک استاد با ادب با دانشجو م...      Neutral   Positive\n",
       "4                                چیزی اضافه ایی نیست      Neutral   Negative\n",
       "5  دقت کنید هر جلسه مطالب را بخونید ارشد شب امتحا...      Neutral   Positive"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment_text</th>\n",
       "      <th>simple_label</th>\n",
       "      <th>bert_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>چیزی اضافه ایی نیست</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>خوب درس نمیده اصلا، نمره ها رو خوب نمیده و اصل...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>در کل اگر که دنبال یک استاد با ادب با دانشجو م...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>چیزی اضافه ایی نیست</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>دقت کنید هر جلسه مطالب را بخونید ارشد شب امتحا...</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-02T15:24:07.990006Z",
     "start_time": "2026-01-02T15:24:07.855080Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ---------------------------------------------------------\n",
    "# SAVE PHASE 3 RESULTS\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "# Save to a new CSV so we don't overwrite the original clean data\n",
    "output_path = '../data/processed/sentiment_data.csv'\n",
    "\n",
    "print(f\"Saving sentiment results to '{output_path}'...\")\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"Data saved safely.\")\n",
    "print(f\"Total Rows: {len(df)}\")"
   ],
   "id": "a058c4c1340394e8",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving sentiment results to '../data/processed/sentiment_data.csv'...\n",
      "Data saved safely.\n",
      "Total Rows: 4548\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "2157d12b2d38941b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
